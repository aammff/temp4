w ke w kwestii bezpieczenstwa

jesli llm nie jest calkowis calkowicie w pelni free open sourceowy czyli i kod i wagi i zrola zrodla treningowe wszystko open source to jest to jesli tak nie jest
 to do zadnych powaznych rzeczy bym czegos takiego nie uzywal   tj firmy ktore robie closed source komercyjne modele tego typu rzeczy jako jakby nie maja zadnego sensu

do rzeczy niepowaznych no to ja zadaje co jakies czas pytania i tu wklejam odpowiedzi czasami no i jakby po moim zyciu cczego doswiadczam to ja nie moge powiedziec
  ogolnie ze to jest bezpieczne wiec jakby  to nie jest tak ze t ja to polecam 

jezeli llm jest calkowicie opensourceowy lacznie z czyli i kod i model i zrodla i wagi i w ogole wszystko ze kazdy moze to wygenerowac zreplikowac ze to jest calkowicie
  totalnie free software i open source to wtey wtedy  byc moze nie wiem mozna sie zastanawiac czy to jest bezpieczne a jesli tak to czy mozna tego uy uzywac do rzeczy

   niepowaznych albo jesli i albo mo z moze i powaznych


a takie cos mi jeszcze do glowy przyszlo nie wiem jak to jest dokladnie robione ale zdaje sie cos takiego mi sie kojarzy cz ze nap np jesli to tam jesli liczone
na liczbach zmiennoprzecinkowych zmiennopozycyjnych nie wiem czy tak to zaleznie od procesora mikroprocesora to takie obo obliczenia niekoniecznie nie zawsze
sa te deterministyczne i moze byc problem z reproducible builds jakby wytrenowaniem ponownym modelu zeby dokladnie to samo wyszlo nie wiem czy tam ten problem
wystepuje ale to uwazac 

no ogolnie nie mialem jakby mocnego sprzetu wystarczajaco zeby jakby samemu trenowac takie modele i tego nie robilem

kiedystam dawno temu na takim z takim prostym chatbotem ro trenowalem da gadealem od zera nie e wiem czy to jest bezpieczne

ogolnie w kwestii tak zwanej pseudo ai czy costam no to jakby jest moze i problem taki ze no bardzo duzo ludzi no jakby to ich myslenie jest wlasnie tego typu
tzn oni jak ten chatgpt no tak jakby wypelniaja te jakby braki wiedzowe takim wypelniaczem z majakow tak nf naprawde no i jakby nawet nie wiedza ze tak robia
no i te systemy to moga cos takiego uswiadomic albo wzmon wzmocninc wzmocnic nawet czyli jakby mozna sie byc mozespodziewac ze jakby ludzie ktorzy tego
uzywaja zaczna byc wybitnie glupi w sposob niezauwazalny dla nich a dla otoczenia roznie  ale moze i tak byc ze ktos sie zorientuje jakby ze czesc jego myslenia
to jakby tak jak ten model dziala   no czy tkso ktos jakby rozumie material wiedzowy czy to tylko powtarza to co w ksiazce przeczytal a czesc tego typu
ajb jakby to co jest generowane no to czasami to za sa zupelnie nowe i jakby nieprzebyte sciezki mentalne i jakby trudno podac status tak wygenerowanego tekstu
czy ten tekstu tekst jest prawdziwy no np no to sa fizlo filozoficzne ale praktyczne zagadnienia dotyczace jakby prawdy czy cos 

takze te rozwazacz rozwazania typu czy ai llm cokolwiek tam jest bezpieczne to jakby dy debatowac o no rozlanej dawno wodzie czy ona moze byc sliska np przy czym
oni nawet ni sie nie zorientowali ze to jakby juz dawno albo cos  tez kweistia co te firmy closedsourceowe jakb jak oni te modele jakby zabezpieczaja przed
generowaniem wg ich niepozadanych tekstow i jaki to ma realny tzw reeany wplyw na wszystkich czy to nie powoduje jakis paradoksalnych zakrzywien w mysleniu
ze wprawdzi ich llm niewygeneruje przepiup przepisu jak w kuchni przyrzadzic costamscostam ale za to no nie powiem co sie stanie i cnikt nie pokojarzy ze to dlactego
takze ml.in. taki argument za po operns opensourceowaniem ze wrazie m no mylse ze trudniej sie przyczepic bo t do jakiejstam niewiadomo czympoduk podyktwowanej
cenzury ktora niewiaodmo jake efekty uob uboczne bedzie miala to jakby no od razy przeyczhoi do glowy zeby sie czepiac i ze to moze byc niep niebezpieczne

ja nie wierze zadnym pseudospecjalistom od mieszania ludziom w glowach bo to w praktyce zawsze sie okazuje ze to sa ludzie efektywnie niepismienni
